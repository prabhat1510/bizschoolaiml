{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d2cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Use the popular Kaggle Credit Card Fraud Dataset, which contains anonymized features (V1â€“V28), \n",
    "Amount, Time, and Class (1 = fraud, 0 = normal).\n",
    "Data set url: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "'''\n",
    "#1. Load and Explore the Dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"D:\\\\Downloads\\\\creditcarddataset\\\\creditcard.csv\")\n",
    "print(data['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58982e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#Normalize Amount and Time\n",
    "#Drop Class for unsupervised learning\n",
    "#Handle imbalance (fraud cases are <0.2%)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data['Time'] = StandardScaler().fit_transform(data['Time'].values.reshape(-1, 1))\n",
    "X = data.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6638ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Apply Unsupervised Models\n",
    "Use anomaly detection algorithms like Isolation Forest and Local Outlier Factor (LOF).\n",
    "'''\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Isolation Forest\n",
    "iso = IsolationForest(contamination=0.002)\n",
    "y_pred_iso = iso.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfe8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.002)\n",
    "y_pred_lof = lof.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d32253d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Predictions\n",
    "#Convert -1 (outlier) and 1 (inlier) to binary fraud predictions.\n",
    "y_pred_iso = [1 if x == -1 else 0 for x in y_pred_iso]\n",
    "y_pred_lof = [1 if x == -1 else 0 for x in y_pred_lof]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ae9b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    284315\n",
      "           1       0.22      0.26      0.24       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.61      0.63      0.62    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n",
      "Local Outlier Factor:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    284315\n",
      "           1       0.00      0.00      0.00       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.50      0.50      0.50    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Against True Labels\n",
    "#Compare predictions with actual Class labels.\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Isolation Forest:\\n\", classification_report(data['Class'], y_pred_iso))\n",
    "print(\"Local Outlier Factor:\\n\", classification_report(data['Class'], y_pred_lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Optimizing fraud detection models is a delicate balance between accuracy, efficiency, and adaptability. \n",
    "Here are some best practices that can help you build robust and scalable systems:\n",
    "\n",
    "ðŸ§ª 1. Rigorous Testing & Validation\n",
    "Use stratified k-fold cross-validation to preserve class imbalance across folds.\n",
    "\n",
    "Evaluate with metrics beyond accuracy: precision, recall, F1-score, and AUC-ROC are crucial for imbalanced datasets.\n",
    "\n",
    "Compare performance against baseline models (e.g., rule-based systems) to ensure meaningful improvements.\n",
    "\n",
    "âš–ï¸ 2. Handle Imbalanced Data Smartly\n",
    "Apply SMOTE or ADASYN for oversampling minority (fraud) class.\n",
    "\n",
    "Use undersampling techniques to reduce majority class noise.\n",
    "\n",
    "Consider ensemble methods like Random Forest or XGBoost, which are more resilient to imbalance3.\n",
    "\n",
    "ðŸ§  3. Model Calibration & Optimization\n",
    "Tune hyperparameters using Bayesian optimization or grid/random search.\n",
    "\n",
    "Regularly calibrate thresholds to reduce false positives and improve precision.\n",
    "\n",
    "Monitor concept drift and data drift to retrain models when patterns shift.\n",
    "\n",
    "ðŸ” 4. Feature Engineering & Selection\n",
    "Use domain knowledge to craft meaningful features (e.g., transaction velocity, device fingerprint).\n",
    "\n",
    "Apply Benfordâ€™s Law to detect anomalies in numeric fields.\n",
    "\n",
    "Leverage graph-based features to capture relationships between entities (e.g., shared IPs or devices).\n",
    "\n",
    "ðŸ§¬ 5. Use Advanced Models Thoughtfully\n",
    "Try Isolation Forest, Autoencoders, or Local Outlier Factor for unsupervised detection.\n",
    "\n",
    "Explore Graph Neural Networks (GNNs) for capturing complex fraud patterns across networks.\n",
    "\n",
    "Use ensemble learning (bagging, boosting, stacking) to combine strengths of multiple models.\n",
    "\n",
    "ðŸ“Š 6. Monitor in Production\n",
    "Track metrics like false positive rate, prediction latency, and model confidence.\n",
    "\n",
    "Use tools like Prometheus and Grafana for real-time monitoring.\n",
    "\n",
    "Implement alerting systems for suspicious spikes or performance degradation.\n",
    "\n",
    "ðŸ›¡ï¸ 7. Security & Compliance\n",
    "Ensure data privacy and secure APIs for model access.\n",
    "\n",
    "Maintain audit trails for predictions and decisions.\n",
    "\n",
    "Align with regulatory standards (e.g., PCI DSS, GDPR) for financial data handling.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
